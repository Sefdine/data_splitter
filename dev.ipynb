{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "input_csv_file = input('Enter the name of the csv file : ')\n",
    "df = pd.read_csv(input_csv_file, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "name = 'superstore_final_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_number(value):\n",
    "    try:\n",
    "        float_value = float(value)\n",
    "        return not isinstance(float_value, (int, float))\n",
    "    except ValueError:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the rows in the dataframe \n",
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Number of lines for json\n",
    "json_percent = (input('Enter the JSON percentage : '))\n",
    "json_percent = 30 if is_not_number(json_percent) else float(json_percent)\n",
    "line_json = int((shuffled_df.shape[0] * json_percent) / 100)\n",
    "\n",
    "# Number of lines for csv\n",
    "csv_percent = (input('Enter the CSV percentage : '))\n",
    "csv_percent = 40 if is_not_number(csv_percent) else float(csv_percent)\n",
    "line_csv = int((shuffled_df.shape[0] * csv_percent) / 100)\n",
    "\n",
    "# Number of lines for database\n",
    "db_percent = (input('Enter the database percentage : '))\n",
    "db_percent = 30 if is_not_number(db_percent) else float(db_percent)\n",
    "line_db = int((shuffled_df.shape[0] * db_percent) / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 30% to json\n",
    "json_df = shuffled_df[:line_json]\n",
    "\n",
    "# Delete the json df from the shuffled\n",
    "shuffled_df.drop(json_df.index, axis='rows', inplace=True)\n",
    "\n",
    "# Create json file\n",
    "json_df.reset_index(drop=True).to_json('json_file.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6860, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2940, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40% for CSV\n",
    "csv_df = shuffled_df[:line_csv]\n",
    "\n",
    "# Delete the csv df to the shuffle\n",
    "shuffled_df.drop(csv_df.index, axis='rows', inplace=True)\n",
    "\n",
    "# Create the csv file\n",
    "csv_df.reset_index(drop=True).to_csv('csv_file.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3920, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30% for DB\n",
    "db_df = shuffled_df[:line_db]\n",
    "\n",
    "# Delete the csv df to the shuffle\n",
    "shuffled_df.drop(db_df.index, axis='rows', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SQL Alchemy\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text, Boolean, Float, Date, text, inspect, UniqueConstraint\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "\n",
    "# Construct the connection string\n",
    "driver = 'ODBC+Driver+18+for+SQL+Server'\n",
    "server_address = 'localhost'\n",
    "database_name = 'Superstore' \n",
    "username = 'SA' \n",
    "password = 'YourPassword123'  \n",
    "\n",
    "# Connection string for master db\n",
    "master_connection_string = f'mssql+pyodbc://{username}:{password}@{server_address}/{database_name}?driver={driver}&Encrypt=No'\n",
    "\n",
    "# Engine for master\n",
    "master_engine = create_engine(master_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class name\n",
    "def class_name(filename):\n",
    "    filename = str.replace(filename, '.csv', '')\n",
    "    filename = str.replace(filename, '_', ' ')\n",
    "    filename = str.replace(filename, '-', ' ')\n",
    "\n",
    "    filename = str.title(filename)\n",
    "    filename = str.replace(filename, ' ', '')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5178/666983151.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  db_df['Order_Date'] = pd.to_datetime(db_df['Order_Date'], dayfirst=True)\n",
      "/tmp/ipykernel_5178/666983151.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  db_df['Ship_Date'] = pd.to_datetime(db_df['Ship_Date'], dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "# Transform date type\n",
    "db_df['Order_Date'] = pd.to_datetime(db_df['Order_Date'], dayfirst=True)\n",
    "db_df['Ship_Date'] = pd.to_datetime(db_df['Ship_Date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('master',),\n",
       " ('tempdb',),\n",
       " ('model',),\n",
       " ('msdb',),\n",
       " ('GithubDB',),\n",
       " ('Superstore',)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create master session\n",
    "MasterSession = sessionmaker(bind=master_engine)\n",
    "master_session = MasterSession()\n",
    "\n",
    "# Retrieve existing databases\n",
    "get_db_query = 'name FROM sys.databases;'\n",
    "\n",
    "result = master_session.query(text(get_db_query)).all()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------- Table creation ----------\n"
     ]
    }
   ],
   "source": [
    "print(' ---------- Table creation ----------')\n",
    "name_class = class_name(input_csv_file)\n",
    "\n",
    "# Create a declarative base\n",
    "Base = declarative_base()\n",
    "\n",
    "# Dynamically create the class with the generated name\n",
    "DynamicTable = type(name_class, (Base,), {\n",
    "    '__tablename__': str.replace(input_csv_file, '.csv', ''),\n",
    "    'id': Column(Integer, primary_key=True, autoincrement=True),\n",
    "    'row_id': Column(Integer, nullable=False),\n",
    "    'order_id': Column(String(), nullable=False),\n",
    "    'order_date': Column(Date, nullable=False),\n",
    "    'ship_date': Column(Date, nullable=False),\n",
    "    'ship_mode': Column(String(), nullable=False),\n",
    "    'customer_id': Column(String(50), nullable=False),\n",
    "    'customer_name': Column(String(), nullable=False),\n",
    "    'segment': Column(String(50), nullable=False),\n",
    "    'country': Column(String(), nullable=False),\n",
    "    'city': Column(String(), nullable=False),\n",
    "    'state': Column(String(), nullable=False),\n",
    "    'postal_code': Column(Float, nullable=True),\n",
    "    'region': Column(String(), nullable=False),\n",
    "    'product_id': Column(String(50), nullable=False),\n",
    "    'category': Column(String(50), nullable=False),\n",
    "    'sub_category': Column(String(50), nullable=False),\n",
    "    'product_name': Column(String(), nullable=False),\n",
    "    'sales': Column(Float, nullable=False)\n",
    "})\n",
    "\n",
    "Base.metadata.create_all(master_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superstore_final_dataset']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the created tables\n",
    "inspector = inspect(master_engine)\n",
    "\n",
    "table_names = inspector.get_table_names()\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5178/64997817.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  db_df['Postal_Code'] = db_df['Postal_Code'].apply(lambda x: 'No postal code' if pd.isnull(x) else x)\n"
     ]
    }
   ],
   "source": [
    "db_df['Postal_Code'] = db_df['Postal_Code'].apply(lambda x: 'No postal code' if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5178/1362648628.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  db_df['Order_Date'] = pd.to_datetime(db_df['Order_Date']).dt.date\n"
     ]
    }
   ],
   "source": [
    "db_df['Order_Date'] = pd.to_datetime(db_df['Order_Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 worked successfully\n",
      "0 has an error\n",
      "1 worked successfully\n",
      "2 worked successfully\n",
      "3 worked successfully\n",
      "4 worked successfully\n",
      "5 worked successfully\n",
      "6 worked successfully\n",
      "7 worked successfully\n",
      "8 worked successfully\n",
      "9 worked successfully\n",
      "10 worked successfully\n",
      "11 worked successfully\n",
      "12 worked successfully\n",
      "13 worked successfully\n",
      "14 worked successfully\n",
      "15 worked successfully\n",
      "16 worked successfully\n",
      "17 worked successfully\n",
      "17 has an error\n",
      "18 worked successfully\n",
      "19 worked successfully\n",
      "20 worked successfully\n",
      "21 worked successfully\n",
      "22 worked successfully\n",
      "23 worked successfully\n",
      "24 worked successfully\n",
      "25 worked successfully\n",
      "26 worked successfully\n",
      "27 worked successfully\n",
      "28 worked successfully\n",
      "29 worked successfully\n",
      "30 worked successfully\n",
      "31 worked successfully\n",
      "32 worked successfully\n",
      "33 worked successfully\n",
      "34 worked successfully\n",
      "35 worked successfully\n",
      "36 worked successfully\n",
      "37 worked successfully\n",
      "38 worked successfully\n",
      "39 worked successfully\n",
      "40 worked successfully\n",
      "41 worked successfully\n",
      "42 worked successfully\n",
      "43 worked successfully\n",
      "44 worked successfully\n",
      "45 worked successfully\n",
      "46 worked successfully\n",
      "47 worked successfully\n",
      "48 worked successfully\n",
      "49 worked successfully\n",
      "50 worked successfully\n",
      "51 worked successfully\n",
      "52 worked successfully\n",
      "53 worked successfully\n",
      "54 worked successfully\n",
      "55 worked successfully\n",
      "56 worked successfully\n",
      "57 worked successfully\n",
      "58 worked successfully\n",
      "59 worked successfully\n",
      "60 worked successfully\n",
      "61 worked successfully\n",
      "62 worked successfully\n",
      "63 worked successfully\n",
      "64 worked successfully\n",
      "65 worked successfully\n",
      "66 worked successfully\n",
      "67 worked successfully\n",
      "68 worked successfully\n",
      "69 worked successfully\n",
      "70 worked successfully\n",
      "71 worked successfully\n",
      "72 worked successfully\n",
      "73 worked successfully\n",
      "74 worked successfully\n",
      "75 worked successfully\n",
      "76 worked successfully\n",
      "77 worked successfully\n",
      "78 worked successfully\n",
      "79 worked successfully\n",
      "80 worked successfully\n",
      "81 worked successfully\n",
      "82 worked successfully\n",
      "83 worked successfully\n",
      "84 worked successfully\n",
      "85 worked successfully\n",
      "86 worked successfully\n",
      "87 worked successfully\n",
      "88 worked successfully\n",
      "89 worked successfully\n",
      "90 worked successfully\n",
      "91 worked successfully\n",
      "92 worked successfully\n",
      "93 worked successfully\n",
      "94 worked successfully\n",
      "95 worked successfully\n",
      "96 worked successfully\n",
      "97 worked successfully\n",
      "98 worked successfully\n",
      "99 worked successfully\n",
      "100 worked successfully\n",
      "101 worked successfully\n",
      "102 worked successfully\n",
      "103 worked successfully\n",
      "104 worked successfully\n",
      "105 worked successfully\n",
      "106 worked successfully\n",
      "107 worked successfully\n",
      "108 worked successfully\n",
      "109 worked successfully\n",
      "110 worked successfully\n",
      "111 worked successfully\n",
      "112 worked successfully\n",
      "113 worked successfully\n",
      "114 worked successfully\n",
      "115 worked successfully\n",
      "116 worked successfully\n",
      "117 worked successfully\n",
      "118 worked successfully\n",
      "119 worked successfully\n",
      "120 worked successfully\n",
      "121 worked successfully\n",
      "122 worked successfully\n",
      "123 worked successfully\n",
      "124 worked successfully\n",
      "125 worked successfully\n",
      "126 worked successfully\n",
      "127 worked successfully\n",
      "128 worked successfully\n",
      "129 worked successfully\n",
      "130 worked successfully\n",
      "131 worked successfully\n",
      "132 worked successfully\n",
      "133 worked successfully\n",
      "134 worked successfully\n",
      "135 worked successfully\n",
      "136 worked successfully\n",
      "137 worked successfully\n",
      "138 worked successfully\n",
      "139 worked successfully\n",
      "140 worked successfully\n",
      "141 worked successfully\n",
      "142 worked successfully\n",
      "143 worked successfully\n",
      "144 worked successfully\n",
      "145 worked successfully\n",
      "146 worked successfully\n",
      "147 worked successfully\n",
      "148 worked successfully\n",
      "149 worked successfully\n",
      "150 worked successfully\n",
      "151 worked successfully\n",
      "152 worked successfully\n",
      "153 worked successfully\n",
      "154 worked successfully\n",
      "155 worked successfully\n",
      "156 worked successfully\n",
      "157 worked successfully\n",
      "158 worked successfully\n",
      "159 worked successfully\n",
      "160 worked successfully\n",
      "161 worked successfully\n",
      "162 worked successfully\n",
      "163 worked successfully\n",
      "164 worked successfully\n",
      "165 worked successfully\n",
      "166 worked successfully\n",
      "167 worked successfully\n",
      "168 worked successfully\n",
      "169 worked successfully\n",
      "170 worked successfully\n",
      "171 worked successfully\n",
      "172 worked successfully\n",
      "173 worked successfully\n",
      "174 worked successfully\n",
      "175 worked successfully\n",
      "176 worked successfully\n",
      "177 worked successfully\n",
      "178 worked successfully\n",
      "179 worked successfully\n",
      "180 worked successfully\n",
      "181 worked successfully\n",
      "182 worked successfully\n",
      "183 worked successfully\n",
      "184 worked successfully\n",
      "185 worked successfully\n",
      "186 worked successfully\n",
      "187 worked successfully\n",
      "188 worked successfully\n",
      "189 worked successfully\n",
      "190 worked successfully\n",
      "191 worked successfully\n",
      "192 worked successfully\n",
      "193 worked successfully\n",
      "194 worked successfully\n",
      "195 worked successfully\n",
      "196 worked successfully\n",
      "197 worked successfully\n",
      "198 worked successfully\n",
      "199 worked successfully\n",
      "200 worked successfully\n",
      "201 worked successfully\n",
      "202 worked successfully\n",
      "203 worked successfully\n",
      "204 worked successfully\n",
      "205 worked successfully\n",
      "206 worked successfully\n",
      "207 worked successfully\n",
      "208 worked successfully\n",
      "209 worked successfully\n",
      "210 worked successfully\n",
      "211 worked successfully\n",
      "212 worked successfully\n",
      "213 worked successfully\n",
      "214 worked successfully\n",
      "215 worked successfully\n",
      "216 worked successfully\n",
      "217 worked successfully\n",
      "218 worked successfully\n",
      "219 worked successfully\n",
      "220 worked successfully\n",
      "221 worked successfully\n",
      "222 worked successfully\n",
      "223 worked successfully\n",
      "224 worked successfully\n",
      "225 worked successfully\n",
      "226 worked successfully\n",
      "227 worked successfully\n",
      "228 worked successfully\n",
      "229 worked successfully\n",
      "230 worked successfully\n",
      "231 worked successfully\n",
      "232 worked successfully\n",
      "233 worked successfully\n",
      "234 worked successfully\n",
      "235 worked successfully\n",
      "236 worked successfully\n",
      "237 worked successfully\n",
      "238 worked successfully\n",
      "239 worked successfully\n",
      "240 worked successfully\n",
      "241 worked successfully\n",
      "242 worked successfully\n",
      "243 worked successfully\n",
      "244 worked successfully\n",
      "245 worked successfully\n",
      "246 worked successfully\n",
      "247 worked successfully\n",
      "248 worked successfully\n",
      "249 worked successfully\n",
      "250 worked successfully\n",
      "251 worked successfully\n",
      "252 worked successfully\n",
      "253 worked successfully\n",
      "254 worked successfully\n",
      "255 worked successfully\n",
      "256 worked successfully\n",
      "257 worked successfully\n",
      "258 worked successfully\n",
      "259 worked successfully\n",
      "260 worked successfully\n",
      "261 worked successfully\n",
      "262 worked successfully\n",
      "263 worked successfully\n",
      "264 worked successfully\n",
      "265 worked successfully\n",
      "266 worked successfully\n",
      "267 worked successfully\n",
      "268 worked successfully\n",
      "269 worked successfully\n",
      "270 worked successfully\n",
      "271 worked successfully\n",
      "272 worked successfully\n",
      "273 worked successfully\n",
      "274 worked successfully\n",
      "275 worked successfully\n",
      "276 worked successfully\n",
      "277 worked successfully\n",
      "278 worked successfully\n",
      "279 worked successfully\n",
      "280 worked successfully\n",
      "281 worked successfully\n",
      "282 worked successfully\n",
      "283 worked successfully\n",
      "284 worked successfully\n",
      "285 worked successfully\n",
      "286 worked successfully\n",
      "287 worked successfully\n",
      "288 worked successfully\n",
      "289 worked successfully\n",
      "290 worked successfully\n",
      "291 worked successfully\n",
      "292 worked successfully\n",
      "293 worked successfully\n",
      "294 worked successfully\n",
      "295 worked successfully\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m):\n\u001b[1;32m      2\u001b[0m     row_id \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(db_df[\u001b[39m'\u001b[39m\u001b[39mRow_ID\u001b[39m\u001b[39m'\u001b[39m][i])\n\u001b[0;32m----> 3\u001b[0m     order_id \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39;49m(db_df[\u001b[39m'\u001b[39;49m\u001b[39mOrder_ID\u001b[39;49m\u001b[39m'\u001b[39;49m])[i]\n\u001b[1;32m      4\u001b[0m     order_date \u001b[39m=\u001b[39m db_df[\u001b[39m'\u001b[39m\u001b[39mOrder_Date\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[1;32m      5\u001b[0m     ship_date \u001b[39m=\u001b[39m db_df[\u001b[39m'\u001b[39m\u001b[39mShip_Date\u001b[39m\u001b[39m'\u001b[39m][i]\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    row_id = int(db_df['Row_ID'][i])\n",
    "    order_id = str(db_df['Order_ID'])[i]\n",
    "    order_date = db_df['Order_Date'][i]\n",
    "    ship_date = db_df['Ship_Date'][i]\n",
    "    ship_mode = db_df['Ship_Mode'][i]\n",
    "    customer_id = str(db_df['Customer_ID'][i])\n",
    "    customer_name = str(db_df['Customer_Name'][i])\n",
    "    segment = str(db_df['Segment'][i])\n",
    "    country = str(db_df['Country'][i])\n",
    "    city = str(db_df['City'][i])\n",
    "    state = str(db_df['State'][i])\n",
    "    postal_code = str(db_df['Postal_Code'][i])\n",
    "    region = str(db_df['Region'][i])\n",
    "    product_id = str(db_df['Product_ID'][i])\n",
    "    category = str(db_df['Category'][i])\n",
    "    sub_category = str(db_df['Sub_Category'][i])\n",
    "    product_name = str(db_df['Product_Name'][i])\n",
    "    sales = float(db_df['Sales'][i])\n",
    "\n",
    "    new_row = {\n",
    "        'row_id': row_id,\n",
    "        'order_id': order_id,\n",
    "        'order_date': order_date,\n",
    "        'ship_date': ship_date,\n",
    "        'ship_mode': ship_mode,\n",
    "        'customer_id': customer_id,\n",
    "        'customer_name': customer_name,\n",
    "        'segment': segment,\n",
    "        'country': country,\n",
    "        'city': city,\n",
    "        'state': state,\n",
    "        'postal_code': postal_code,\n",
    "        'region': region,\n",
    "        'product_id': product_id,\n",
    "        'category': category,\n",
    "        'sub_category': sub_category,\n",
    "        'product_name': product_name,\n",
    "        'sales': sales\n",
    "    }\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Create an instance of the class\n",
    "        new_row_instance = DynamicTable(**new_row)\n",
    "        \n",
    "        master_session.add(new_row_instance)\n",
    "        print(i, 'worked successfully')\n",
    "        master_session.commit()\n",
    "    except:\n",
    "        print(i, 'has an error')\n",
    "        master_session.rollback()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
